# Belief-Networks-Hidden-Markov-Models
Fall 2025 CS 362/562

The Hidden Markov Model (HMM) for spell correction revealed several interesting patterns about its operational behavior when processing correctly and incorrectly spelled words. The algorithm incorrectly changed the correct spelling of “layer” into “laser” during its operation. The model uses transition and emission probabilities which it learned from the aspell.txt dataset to make its predictions. The HMM evaluated all possible letter sequences to determine that “laser” had higher probability than “layer” based on its learned statistical data. The algorithm chooses the letter sequence which produces the highest probability based on the observed training data without understanding what correct spelling means. The algorithm tends to misinterpret words that contain letters which appear frequently in the training dataset. The model produced two incorrect corrections by transforming “committee” into “committed” and “your” into “court”. The model chose to replace correct words with incorrect predictions because these sequences appeared more frequently in the training data.

The system produced incorrect word corrections during specific instances. The system transformed “buton” into “susan” instead of fixing the typo which resulted in an incorrect output. The system failed to find an appropriate dictionary match because the input did not contain any words that matched the emission and transition probabilities learned by the model. The HMM system together with the closest-word function picked a word that seemed most probable based on learned probabilities although it did not match the input well. The model produces unlikely correction results because it relies on training data that contains biased information about word frequencies and uncommon letter patterns. The system produces errors when it uses letter emission probabilities together with letter transition probabilities to override basic similarity assessments.

However, the algorithm does succeed in many cases. A representative example is amature, which was correctly corrected to amateur. The model used its learned probability values to detect the single-letter mistake and generate the most probable correct word. The success in this scenario can be attributed to the closeness of the typed word to the correct spelling and the high probability of the transition and emission patterns that matched amateur. The algorithm successfully identified the observed letter sequence as a highly probable word in the dictionary because HMMs excel at processing small errors that occur in limited areas.

Finally, the performance of the algorithm would differ considerably in a real-world context depending on the training data. The model would achieve better results when trained with real internet typos because it would discover actual human typing mistakes which include letter exchanges and missing characters and adjacent keyboard errors. The training data contains synthetic or programmatically generated typos which do not follow real typing behavior so the model might develop poor generalization abilities. The model would achieve better results in correcting standard writing mistakes when trained on actual data but it could struggle with identifying unusual writing patterns that contain infrequent words. The performance of an HMM-based spell corrector depends on three main factors which include training data quality and diversity and representativeness. The system needs to find an optimal balance between statistical model accuracy and real-world correction precision.
